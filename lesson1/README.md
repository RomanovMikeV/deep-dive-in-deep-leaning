# Инструкции

## Постановка задачи

В этом уроке мы решим задачу регрессии при помощи нейронной сети. Мы будем
предсказывать значение некоторой простой функции (например, синуса или косинуса)
в некоторой точке <img src="/lesson1/tex/332cc365a4987aacce0ead01b8bdcc0b.svg?invert_in_darkmode&sanitize=true" align=middle width=9.39498779999999pt height=14.15524440000002pt/>.

Иными словами, мы сделаем сеть, которая делает аппроксимацию некоторой
неизвестной (скрытой) зависимости <img src="/lesson1/tex/7997339883ac20f551e7f35efff0a2b9.svg?invert_in_darkmode&sanitize=true" align=middle width=31.99783454999999pt height=24.65753399999998pt/>.

Стоит отметить, что это можно сделать с любой точностью при помощи сигмоидной
нейронной сети (функции активации -- сигмоиды) для ограниченной функции <img src="/lesson1/tex/7997339883ac20f551e7f35efff0a2b9.svg?invert_in_darkmode&sanitize=true" align=middle width=31.99783454999999pt height=24.65753399999998pt/> с конечным числом разрывов.

## Инструкции для решения
### Create a Dataset / Сделайте датасет

В этом уроке мы сделаем датасет сами. Для этого мы возьмем некоторую функцию <img src="/lesson1/tex/190083ef7a1625fbc75f243cffb9c96d.svg?invert_in_darkmode&sanitize=true" align=middle width=9.81741584999999pt height=22.831056599999986pt/>
(ограниченную, имеющую не больше, чем счетное количество разрывов), и сделаем
набор пар <img src="/lesson1/tex/20886c95cad07a2e07cc69a3cae30aee.svg?invert_in_darkmode&sanitize=true" align=middle width=91.05878099999998pt height=24.65753399999998pt/>, где <img src="/lesson1/tex/1cd32b0756da515bc59142b9318ff797.svg?invert_in_darkmode&sanitize=true" align=middle width=11.323291649999991pt height=14.15524440000002pt/> -- некоторый шум, который
мы будем генерировать сами. Причина, по которой мы добавляем шум в наши данные
заключается в том, что всегда, когда мы производим измерения, мы получаем
значение с некоторой точностью. Мы рассмотрим случай, когда в каждой точке <img src="/lesson1/tex/9fc20fb1d3825674c6a279cb0d5ca636.svg?invert_in_darkmode&sanitize=true" align=middle width=14.045887349999989pt height=14.15524440000002pt/> шум независим от значений в других точках и одинаково распределен.

В реальной жизни у нас будет просто набор пар <img src="/lesson1/tex/9cb3b82be5418fbb7dad8a5c4ae38d9b.svg?invert_in_darkmode&sanitize=true" align=middle width=34.88399804999999pt height=14.15524440000002pt/>, в качестве датасета,
по которым необходимо восстановить скрытую зависимость <img src="/lesson1/tex/190083ef7a1625fbc75f243cffb9c96d.svg?invert_in_darkmode&sanitize=true" align=middle width=9.81741584999999pt height=22.831056599999986pt/> такую, что
<p align="center"><img src="/lesson1/tex/2398b6b54c85aadd6104d17fb77bebbf.svg?invert_in_darkmode&sanitize=true" align=middle width=104.3349714pt height=16.438356pt/></p>.

Для выполнения этого задания создайте файл sine_dataset.py и
1) сделайте в нем два класса: ```DataSetIndex``` и ```DataSet```

2) для класса ```DataSetIndex``` сделайте
метод
```__init__(self, seed=0, n_items=1000, low=-10.0, high=10.0, noise=0.1)```.

* Здесь инициализируйте генератор случайных чисел numpy значением ```seed```

* создайте случайный набор координат, равномерно распределенных от ```low``` до
```high```

* посчитайте в этих координатах значение функции <img src="/lesson1/tex/fb9dd87ee5c46cc6f1bac5ad989387d4.svg?invert_in_darkmode&sanitize=true" align=middle width=45.416004149999985pt height=24.65753399999998pt/>

* сгенерируйте
вектор шума соответствующего размера (нормальный шум со матожиданием 0 и
стандартным отклонением ```noise_level```)

* добавьте шум к значениям функции

* разбейте координаты и значения на три куска: ```train```, ```valid``` и ```test``` (```valid``` и ```test```
должны составлять соответственно по 10% и 50% от всей выборки).

* Сделайте переменную ```order``` для каждого куска датасета. В ней будет храниться порядок следования элементов датасета. Для ```train``` сделайте
случайный порядок индексов (при помощи ```numpy.random.permutation```), для ```valid``` и ```test``` сделайте порядок от 0 до N (```numpy.arange```).

3) для класса ```DataSet``` сделайте метод
```__init__(self, ds_index, mode='train')```. В нем сохраните ```ds_index``` и ```mode```
в обьект ```self``` класса ```DataSet```.

4) для класса ```DataSet``` сделайте метод ```__len__(self)```, который будет
возвращать количество примеров в ```self```. Помните, что количество примеров
разное для ```train```, ```valid``` и ```test``` кусков датасета.

5) для класса ```DataSet``` сделайте метод ```__getitem__(self, index)```,
который вернет два списка: входное значение для нашей сети, обернутое в список, и целевое значение для выходов, оберутое в список.

6) для класса ```DataSet``` сделайте метод
```shuffle(self)```. Этот метод будет вызываться в начале каждой эпохи (эпоха -- период, за который нейросеть просматривает по разу все обучающие примеры) и
перемешивать тренировочную выборку для эпохи. Валидационную и тестовую выборку он перемешивать не должен.

7) протестируйте датасет. Посмотрите, что возвращает ```DataSet``` при индексации
(например, при вытаскивании элемента с номером 0). Проверьте, что ```DataSet```
работает во всех режимах (```train```, ```valid```, ```test```) для всех
индексов. Посмотрите, как выглядят наши данные: сделайте график при помощи
Jupyter Notebook значений <img src="/lesson1/tex/332cc365a4987aacce0ead01b8bdcc0b.svg?invert_in_darkmode&sanitize=true" align=middle width=9.39498779999999pt height=14.15524440000002pt/> и <img src="/lesson1/tex/7997339883ac20f551e7f35efff0a2b9.svg?invert_in_darkmode&sanitize=true" align=middle width=31.99783454999999pt height=24.65753399999998pt/>.

### Сделайте модель

Мы уже сделали скрипт датасета -- это половина работы. Вторая половина --
определиться с архитектурой модели, лосс-функцией, метриками, оптимизатором.

1) Для начала сделаем архитектуру модели. Для этого определим класс ```Model``` в
```model.py```. Он должен быть унаследован от класса ```torch.nn.Module```.

2) В этом классе сделайте функцию ```__init__(self)```, в которой будут определены все
элементы архитектуры. В нашем случае нейронная сеть будет состоять из двух
линейных слоев (скрытого и выходного). Нужно создать эти слои в __init__.
Количество скрытых нейронов можно сделать параметром сети.

3) Далее, нужно определить, как будет вычисляться результат работы сети.
Создайте метод ```forward``` в классе ```Model```. Этот метод принимает один аргумент
(список входов в сеть) и возвращает список результатов (список из одного тензора в нашем случае).
Производите вычисления следующим образом:
вход -> скрытый слой -> сигмоида -> выходной слой.

Таким образом, мы сделали нашу нейронную сеть.

### Сделайте обработчик модели (Socket)

В этом классе находится вся информация о том, как взаимодействовать с моделью.

В этом классе нужно определить следующие методы: ```__init__``` -- конструктор,
```criterion``` -- лосс-функция, ```metrics``` -- метрики. Остальное определять
в этом задании не обязательно.

1) Сделайте метод ```__init__(self, model)```: сохраните модель в поле self.model,
определите тренируемые слои (поле ```self.train_modules```, в этом задании это вся
модель, поэтому можно в качестве тренируемых слоев передать ```self.model```),
задайте оптимизатор self.optimizer (пусть в нашем случае это будет Adam со
скоростью обучения ```3.0e-4```).

2) Сделайте метод ```criterion(self, output, target)```. Сюда будут приходить
списки результатов работы модели и целевых значений. В нашем случае эти списки
будут содержать по одному тензору. В нашем случае функцией ошибки будет
среднеквадратичное отклонение (Mean Squared Error, MSE). Используя операции
пакета torch расчитайте значение MSE между output[0] и target[0] и верните
результат.

3) Сделайте метод ```metrics(self, output, target)```. Сюда будут приходить точно
такие же списки, как и в метод ```criterion```. В этом задании мы будем
использовать метрику "доля точек с ошибкой меньше заданной":
<p align="center"><img src="/lesson1/tex/864fb8323dbdcc47539e9f077d976e2c.svg?invert_in_darkmode&sanitize=true" align=middle width=448.80627825pt height=62.6919018pt/></p>
Здесь <img src="/lesson1/tex/8e6f8772884838ad7db8233311f53511.svg?invert_in_darkmode&sanitize=true" align=middle width=37.47063044999999pt height=31.50689519999998pt/> -- результат работы нейронной сети в точке <img src="/lesson1/tex/9fc20fb1d3825674c6a279cb0d5ca636.svg?invert_in_darkmode&sanitize=true" align=middle width=14.045887349999989pt height=14.15524440000002pt/>, <img src="/lesson1/tex/2b442e3e088d1b744730822d18e7aa21.svg?invert_in_darkmode&sanitize=true" align=middle width=12.710331149999991pt height=14.15524440000002pt/> --
таргетное значение. Возьмите <img src="/lesson1/tex/ccc8c36bd75b0a3fd820174d730dea02.svg?invert_in_darkmode&sanitize=true" align=middle width=150.96466109999997pt height=21.18721440000001pt/>. Это и будут
наши метрики. Верните словарь из метрик.

# Тренировка модели

1) Запустите процесс тренировки
```
scorch-train --model model.py --dataset dataset.py --epochs 10 -cp 10_epochs
```

2) Также сделайте обучение на протяжении 100 эпох
```
scorch-train --model model.py --dataset dataset.py --epochs 100 -cp 100_epochs
```

3) Оцените визульно качество обучения:

* сделайте тестовый прогон модели с 10 эпохами
  ```
  scorch-test --model model.py --dataset dataset.py -cp 10_epochs --prefix 10_epochs
  ```

* cделайте тестовый прогон модели со 100 эпохами
  ```
  scorch-test --model model.py --dataset dataset.py -cp 100_epochs --prefix 100_epochs
  ```

4) считайте результат из ноутбука и сделайте график получившейся функции

# Помощь

Пример решения задачи можно найти в файле ```Solution.ipynb.pdf```
